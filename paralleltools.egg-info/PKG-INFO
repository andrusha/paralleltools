Metadata-Version: 1.0
Name: paralleltools
Version: 0.0.2
Summary: A collection of basic list functions which can be run in parallel mode (both sync or async).
Home-page: http://github.com/andrusha/paralleltools
Author: Andrew Korzhuev
Author-email: korzhuev@andrusha.me
License: Copyright (C) 2012 Andrey Korzhuev

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Description: License
        =======
        
        This software is free to use and modify, and licensed under MIT License (see LICENSE file).  
        
        
        About
        =====
        
        Parallel tools (named in manner to itertools & functools) is a set of commonly used list traversal functions, which is working in parallel (fault-tolerant) in synchronous or asynchronous manner.  
        
        Implementation is based on python `threading` module, so be aware of GIL.  
        
        Currently implemented functions are (both sync & async):  
        
        * `filter` - filters the list by predicate you provide;   
        * `map` - applies a function to each element of the list.  
        
        **Important**: Due to nature of parallel processing the order of results isn't guranteed. Although, function is returns a `list` because the objects you want to process might not be hashable, hence you can't use a `set`.  
        
        Usage
        =====
        
        This module is useful if you do I/O-heavy task, e.g. collecting a RSS-feeds or determining if site is alive or not.
        
        Map
        ---
        
        Synchronous with default parameters:  
        
        ```python
        import urllib
        import paralleltools
        
        feeds = ['http://xkcd.com/rss.xml',
                 'http://www.smbc-comics.com/rss.php']
        
        comics = paralleltools.map(urllib.urlopen, feeds)
        ```
        
        Asynchronous:  
        
        ```python
        import Image
        import logging
        import paralleltools
        
        images = ['cat1.jpg', 'cat2.jpg', 'cat3.jpg', ..., 'catN.jpg']
        
        def rotate(img):
        	Image.open(img).rotate(720).save(img)
        	return img
        
        def done(results):
            logging.info("Yay!")
        
        paralleltools.async_map(rotate, images, threads=20, callback=done)
        logging.info("Cats being processed")
        ```
        
        Filter
        ------
        
        Synchronous with default parameters:  
        
        ```python
        import ping
        import paralleltools
        
        sites = ['http://github.com',
        		 'http://python.org',
        		 'http://no-one-read-the-docs-any.way']
        
        def alive(site):
        	return ping(site) > 100
        
        paralleltools.filter(alive, sites)
        ```
        
        Asynchronous:  
        
        ```python
        import lxml
        import paralleltools
        
        docs = ['wikileaks_doc1.xml', 'wikileaks_doc2.xml', 'wikileaks_doc3.xml']
        
        def valid(doc):
        	try:
        		lxml.etree.parse(doc)
        		return True
        	except lxml.etree.XMLSyntaxError:
        		return False
        
        def upload_documents(docs):
        	# conspiracy
        
        paralleltools.async_filter(valid, docs, callback=upload_documents)
        find_more_documents()  # while these are processed
        ```
        
        API
        ---
        
        Methods available:  
        
        * `map`
        * `async_map`
        * `filter`
        * `async_filter`
        
        Parameters:
        
        * `function`
        * `iterable`
        * `threads` (default = 5)
        * `result_callback` (sync) or `callback` (async)
        
        You can create your own workers by extending `AbstractWorker` in `workers.py` module. Or altering supervisor behaviour in `supervisors.py`.
Keywords: parallel threading map filter reduce async
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 2.6
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.2
Classifier: Operating System :: OS Independent
